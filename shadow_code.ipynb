{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nu_dataset = NuSceneDataset(**args)\n",
    "\n",
    "input_dict = nu_dataset.__getitem__(idx) # 获取元信息（文件路径、真值标注）\n",
    "load_images(input_dict, **args)\n",
    "load_points(input_dict, **args)\n",
    "resize_images(input_dict, **args)\n",
    "get_gt(input_dict, **args)\n",
    "others(input_dict, **args)\n",
    "Collect3D(input_dict, **args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse4dNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Sparse4dNet, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, **data):\n",
    "        if self.training:\n",
    "            return self.forward_train(**data)\n",
    "        else:\n",
    "            return self.forward_test(**data)\n",
    "    \n",
    "    def foward_train(self, **data):\n",
    "        imgs = data['imgs']\n",
    "        # bs * n_cams * 3 * W * H -> n_levels * [(bs* n_cam) * n_chanels * W/@ * H/@]\n",
    "        features = self.extract_feat(imgs) \n",
    "\n",
    "        anchors, cls = self.head(features, data)\n",
    "\n",
    "        loss = self.head.loss(anchors, cls, data)\n",
    "\n",
    "    def extract_feat(self, imgs):\n",
    "        # bs * n_cams * 3 * W * H -> n_levels * [bs * n_cam * 3 * W/@ * H/@]\n",
    "        features = self.img_backbone(imgs)\n",
    "        features = self.img_neck(features)\n",
    "        return features\n",
    "    \n",
    "class Sparse4dHead(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Sparse4dHead, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def foward(self, features, more_features, data):\n",
    "\n",
    "        # instance features/anchors\n",
    "        instance_features = \n",
    "        instance_anchors = \n",
    "        more_instance_features = \n",
    "        more_instance_anchors = \n",
    "\n",
    "        # SA\n",
    "        instance_features = SA(instance_features, query_pos = instance_anchors)\n",
    "\n",
    "        # residual connect\n",
    "\n",
    "        # feature aggregation\n",
    "        keypoints_fix = \n",
    "        keypoints_learned = kps(instance_features)\n",
    "        instance_keypoints, more_instance_keypoints = attach(keypoints_fix, keypoints_learned, instance_anchors)\n",
    "\n",
    "        features_sampled = sample(instance_keypoints, features, more_instance_keypoints, more_features)\n",
    "        weights = weights_map(instance_anchors)\n",
    "        features_sampled = weight_sum(features_sampled, weights) # multi-level multi-view\n",
    "\n",
    "        weight_depth = get_weight_depth(instance_anchors, instance_features)\n",
    "        features_sampled = weights_depth * features_sampled\n",
    "\n",
    "        features_sampled = temporal_fusion(features_sampled)\n",
    "        features_sampled = keypoints_fusion(features_sampled)\n",
    "\n",
    "        instance_features = fusion(instance_features, features_sampled)\n",
    "\n",
    "        # refine\n",
    "        anchors = anchor_head(features_sampled)\n",
    "        clses = cls_head(features_sampled)\n",
    "\n",
    "        # loops-->\n",
    "\n",
    "        return anchors, clses\n",
    "\n",
    "    def loss(self, anchors, clses, anchors_gt, clses_gt):\n",
    "        loss = {}\n",
    "\n",
    "        # match\n",
    "        cls_cost = cal_cls_cost(clses, clses_gt) # focal loss - pos_loss- neg_loss // * cls_weight\n",
    "        reg_cost = cal_reg_cost(anchors, anchors_gt) # L1 distance  // * reg_weight\n",
    "        cost = cls_cost + reg_cost\n",
    "        match_result = match(cost)\n",
    "\n",
    "        # 监督信号\n",
    "        anchors_target = get_target_anchors(match_result, anchors, anchors_gt)\n",
    "        clses_target = get_target_clses(match_result, clses)\n",
    "\n",
    "        loss['cls_loss'] = focal_loss(clses, clses_target, avg_size = @)\n",
    "        loss['reg_loss'] = smooth_l1(anchors, anchors_target, avg_size = @)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "model = Model(**args)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
